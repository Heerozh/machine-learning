{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习工程师纳米学位\n",
    "## 深度学习\n",
    "## 项目：搭建一个数字识别项目\n",
    "\n",
    "在此文件中，我们提供给你了一个模板，以便于你根据项目的要求一步步实现要求的功能，进而完成整个项目。如果你认为需要导入另外的一些代码，请确保你正确导入了他们，并且包含在你的提交文件中。以**'练习'**开始的标题表示接下来你将开始实现你的项目。注意有一些练习是可选的，并且用**'可选'**标记出来了。\n",
    "\n",
    "在此文件中，有些示例代码已经提供给你，但你还需要实现更多的功能让项目成功运行。除非有明确要求，你无须修改任何已给出的代码。以'练习'开始的标题表示接下来的代码部分中有你必须要实现的功能。每一部分都会有详细的指导，需要实现的部分也会在注释中以'TODO'标出。请仔细阅读所有的提示！\n",
    "\n",
    "除了实现代码外，你还必须回答一些与项目和你的实现有关的问题。每一个需要你回答的问题都会以**'问题 X'**为标题。请仔细阅读每个问题，并且在问题后的**'回答'**文字框中写出完整的答案。我们将根据你对问题的回答和撰写代码所实现的功能来对你提交的项目进行评分。\n",
    "\n",
    ">**注意：** Code 和 Markdown 区域可通过 **Shift + Enter** 快捷键运行。此外，Markdown可以通过双击进入编辑模式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## 步骤 1: 设计并测试一个模型架构\n",
    "设计并实现一个能够识别数字序列的深度学习模型。你可以通过连接[notMNIST](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html)或者是[MNIST](http://yann.lecun.com/exdb/mnist/)的字符来合成数据来训练这个模型。为了产生用于测试的合成数字序列，你可以进行如下的设置：比如，你可以限制一个数据序列最多五个数字，并在你的深度网络上使用五个分类器。同时，你有必要准备一个额外的“空白”的字符，以处理相对较短的数字序列。\n",
    "\n",
    "在思考这个问题的时候有很多方面可以考虑：\n",
    "- 你的模型可以基于深度神经网络或者是卷积神经网络。\n",
    "- 你可以尝试是否在softmax分类器间共享权值。\n",
    "- 你还可以在深度神经网络中使用循环网络来替换其中的分类层，并且将数字序列里的数字一个一个地输出。\n",
    "\n",
    "你可以使用 Keras 来构建你的模型，[这里](https://keras.io/)了解更多。\n",
    "\n",
    "这里有一个[发表的关于这个问题的基准模型的论文](https://github.com/nd009/machine-learning/blob/zh-cn/projects/digit_recognition/42241.pdf) [（视频）](http://cn-static.udacity.com/mlnd/videos/ICLR14_%20Goodfellow.mp4)的例子。我们并不要求你构建的模型架构跟论文上一摸一样或者达到它那样的模型表现。这里紧紧是展示一个解决这个问题的例子。我们鼓励你采用不同的架构，来看看哪种表现对你来说最好。你也可以看论坛上关于论文中架构的[讨论](https://discussions.udacity.com/t/goodfellow-et-al-2013-architecture/202363)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实现\n",
    "使用下面的代码单元（必要的话可以使用多个代码单元）来实现你项目的第一步。一旦你完成了你的实现并且获得了满意的结果，请确认全面回答下面相关的问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "### 在这里实现你的代码  \n",
    "### 必要的话你可以随意添加更多的代码单元 \n",
    "from __future__ import print_function\n",
    "from imp import reload\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Image\n",
    "import random\n",
    "import os\n",
    "\n",
    "import mnist_seq\n",
    "mnist_seq = reload(mnist_seq)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "num_seqlen = 5\n",
    "num_labels = mnist_seq.DIGITS\n",
    "\n",
    "# Generate training data\n",
    "random.seed(1)\n",
    "train_data, train_labs = mnist_seq.gen_data(10000, seqs=num_seqlen)\n",
    "test_data, test_labs = mnist_seq.gen_data(1000, test=True, seqs=num_seqlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0   1   2   3   4   5   6   7   8   9  B\n",
      "[[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] (5, 11)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABlCAYAAABdnhjZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMfH/pBxzIYq7f9cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15b3748ec88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test display\n",
    "plt.figure()\n",
    "rndsel = random.randint(0, len(train_data)-1)\n",
    "plt.imshow(train_data[rndsel][:, :, -1]) \n",
    "print('   0   1   2   3   4   5   6   7   8   9  B')\n",
    "print(train_labs[rndsel], train_labs[rndsel].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def argmaxlab(lab):\n",
    "    return np.argmax(lab.reshape(-1, num_seqlen, num_labels), 2)\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(argmaxlab(predictions) == argmaxlab(labels))\n",
    "          / (predictions.shape[0] * num_seqlen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"data:0\", dtype=float32)\n",
      "Tensor(\"predict/conv1/MaxPool:0\", shape=(?, 14, 70, 32), dtype=float32)\n",
      "Tensor(\"predict/conv2/MaxPool:0\", shape=(?, 7, 35, 64), dtype=float32)\n",
      "Tensor(\"predict/conv3/MaxPool:0\", shape=(?, 4, 18, 64), dtype=float32)\n",
      "Tensor(\"predict/fully_connected/dropout/mul:0\", shape=(?, 256), dtype=float32)\n",
      "Tensor(\"predict/conv1_1/MaxPool:0\", shape=(1000, 14, 70, 32), dtype=float32)\n",
      "Tensor(\"predict/conv2_1/MaxPool:0\", shape=(1000, 7, 35, 64), dtype=float32)\n",
      "Tensor(\"predict/conv3_1/MaxPool:0\", shape=(1000, 4, 18, 64), dtype=float32)\n",
      "Tensor(\"predict/fully_connected_1/Relu:0\", shape=(1000, 256), dtype=float32)\n",
      "None\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "None values not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-b4010d969aa0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m                      save='first.model')\n\u001b[1;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\udacity\\machine-learning\\projects\\digit_recognition\\helper.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x_data, y_predict, vail_data, vail_labs)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf_train_labs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[1;31m# Optimizer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc_optimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn.py\u001b[0m in \u001b[0;36msigmoid_cross_entropy_with_logits\u001b[0;34m(logits, targets, name)\u001b[0m\n\u001b[1;32m    434\u001b[0m   \"\"\"\n\u001b[1;32m    435\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"logistic_loss\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"logits\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m     \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"targets\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m           \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    174\u001b[0m                                          as_ref=False):\n\u001b[1;32m    175\u001b[0m   \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0mtensor_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[0;32m--> 165\u001b[0;31m       tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    166\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    358\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"None values not supported.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m     \u001b[1;31m# if dtype is provided, forces numpy array to be the type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[1;31m# provided if possible.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: None values not supported."
     ]
    }
   ],
   "source": [
    "import helper\n",
    "helper = reload(helper)\n",
    "\n",
    "# Main Model\n",
    "def my_model(x_input, drop=None):\n",
    "    depth1, depth2, depth3, depth4 = 32, 64, 64, 256\n",
    "    with tf.variable_scope(\"conv1\"):\n",
    "        relu = helper.conv_relu(x_input, kernel_shape=[3, 3, 1, depth1],  pool=True)\n",
    "        \n",
    "    with tf.variable_scope(\"conv2\"):\n",
    "        relu = helper.conv_relu(relu, kernel_shape=[3, 3, depth1, depth2],  pool=True)\n",
    "        \n",
    "    with tf.variable_scope(\"conv3\"):\n",
    "        relu = helper.conv_relu(relu, kernel_shape=[3, 3, depth2, depth3], pool=True)\n",
    "        \n",
    "    with tf.variable_scope(\"fully_connected\"):\n",
    "        shape = relu.get_shape().as_list()\n",
    "        csize = shape[1] * shape[2] * shape[3]\n",
    "        reshape = tf.reshape(relu, [-1, csize])    \n",
    "        relu = helper.relu(reshape, [csize, depth4], drop=drop)\n",
    "        \n",
    "    with tf.variable_scope(\"out\"):\n",
    "        weights, biases = helper.var([depth4, num_labels * num_seqlen])\n",
    "        return tf.matmul(relu, weights) + biases\n",
    "\n",
    "clf = helper.Learner(my_model, accuracy, \n",
    "                     steps=601, batch_size=128,\n",
    "                     loss=tf.nn.sigmoid_cross_entropy_with_logits,\n",
    "                     optimizer=tf.train.AdamOptimizer,\n",
    "                     save='first.model')\n",
    "\n",
    "clf.fit(train_data, train_labs, test_data, test_labs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"The name 'drop:0' refers to a Tensor which does not exist. The operation, 'drop', does not exist in the graph.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-764840a7ccd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m clf = helper.Learner(my_model, accuracy, \n\u001b[1;32m      3\u001b[0m                      save='first.model')\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"1000\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msample_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pick a random image index\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\udacity\\machine-learning\\projects\\digit_recognition\\helper.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, step)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'predict/out/add:0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_train_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data:0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_drop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'drop:0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mget_tensor_by_name\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2465\u001b[0m       raise TypeError(\"Tensor names are strings (or similar), not %s.\"\n\u001b[1;32m   2466\u001b[0m                       % type(name).__name__)\n\u001b[0;32m-> 2467\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_graph_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2468\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2469\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_next_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2317\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2318\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_as_graph_element_locked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2358\u001b[0m           raise KeyError(\"The name %s refers to a Tensor which does not \"\n\u001b[1;32m   2359\u001b[0m                          \u001b[1;34m\"exist. The operation, %s, does not exist in the \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2360\u001b[0;31m                          \"graph.\" % (repr(name), repr(op_name)))\n\u001b[0m\u001b[1;32m   2361\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mout_n\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"The name 'drop:0' refers to a Tensor which does not exist. The operation, 'drop', does not exist in the graph.\""
     ]
    }
   ],
   "source": [
    "helper = reload(helper)\n",
    "clf = helper.Learner(my_model, accuracy, \n",
    "                     save='first.model')\n",
    "clf.load(step=\"1000\")\n",
    "\n",
    "sample_idx = np.random.randint(len(test_data))  # pick a random image index\n",
    "sample_image = test_data[sample_idx, :]  # extract a 2D slice\n",
    "plt.imshow(sample_image.reshape(28, 28*5))  # display it\n",
    "\n",
    "#saver = tf.train.Saver()\n",
    "predict_lab = clf.predict([[sample_image]])\n",
    "        \n",
    "plt.xlabel(  predict_lab[0] )\n",
    "print(predict_lab)\n",
    "print((100.0 * np.sum(predict_lab == argmaxlab(test_labs[sample_idx]))\n",
    "          / (1 * num_seqlen)))\n",
    "t =( predict_lab == argmaxlab(test_labs[sample_idx]))\n",
    "print(t, np.sum(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 1.017308\n",
      "Minibatch accuracy: 10.3%\n",
      "Test accuracy: 12.3%\n",
      "Minibatch loss at step 20: 0.269068\n",
      "Minibatch accuracy: 32.5%\n",
      "Test accuracy: 35.4%\n",
      "Minibatch loss at step 40: 0.233555\n",
      "Minibatch accuracy: 39.8%\n",
      "Test accuracy: 45.9%\n",
      "Minibatch loss at step 60: 0.207109\n",
      "Minibatch accuracy: 46.2%\n",
      "Test accuracy: 59.1%\n",
      "Minibatch loss at step 80: 0.181550\n",
      "Minibatch accuracy: 56.9%\n",
      "Test accuracy: 70.1%\n",
      "Minibatch loss at step 100: 0.147620\n",
      "Minibatch accuracy: 66.6%\n",
      "Test accuracy: 79.6%\n",
      "Test accuracy: 79.6%\n"
     ]
    }
   ],
   "source": [
    "#训练太慢，明天来改快，顺便重启系统测试下gpu\n",
    "#cd C:\\Program Files\\Anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\n",
    "#python -m tensorflow.models.image.mnist.convolutional\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  ..., \n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  ..., \n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  ..., \n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " ..., \n",
      " [[ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  ..., \n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  ..., \n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  ..., \n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 0.]]]\n",
      "[[0 0 0 0 0]]\n",
      "0.0\n",
      "[[False False False False False]] 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABzCAYAAACIEflfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxpiI+C+GvVKRXSRSngAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23c04c672e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_idx = np.random.randint(len(test_data))  # pick a random image index\n",
    "sample_image = test_data[sample_idx, :]  # extract a 2D slice\n",
    "plt.imshow(sample_image.reshape(image_hight, image_width))  # display it\n",
    "\n",
    "#saver = tf.train.Saver()\n",
    "with tf.Session(graph=graph) as session:\n",
    "    saver.restore(session, tf.train.latest_checkpoint('.'))\n",
    "    predict = tf.argmax(tf.reshape(logits, [-1, num_seqlen, num_labels]), 2)\n",
    "    predict_lab = session.run(predict, feed_dict={tf_train_data: [sample_image]})\n",
    "        \n",
    "plt.xlabel(  predict_lab[0] )\n",
    "print(predict_lab)\n",
    "print((100.0 * np.sum(predict_lab == argmaxlab(test_labs[sample_idx]))\n",
    "          / (1 * num_seqlen)))\n",
    "t =( predict_lab == argmaxlab(test_labs[sample_idx]))\n",
    "print(t, np.sum(t))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 1\n",
    "_你为解决这个问题采取了什么方法？_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**回答：** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 2\n",
    "_你最终的模型架构是什么样的？（什么类型的模型，层数，大小, 连接性等）_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**回答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 3\n",
    "_你是如何训练你的模型的？你是如何合成数据集的？_请同时包括你创建的合成数据中的一些示例图像。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**回答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## 步骤 2: 在真实数据集上训练一个模型\n",
    "\n",
    "一旦你确定好了一个好的模型架构，你就可以开始在真实的数据上训练你的模型了。特别地，[街景房屋门牌号(SVHN)](http://ufldl.stanford.edu/housenumbers/)数据集是一个大规模的，从谷歌街景数据中采集的门牌号数据。在这个更有挑战性的数据集（这里数字不是整齐排列的，并且会有各种倾斜、字体和颜色）上训练，可能意味着你必须做一些超参数探索以获得一个表现良好的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实现\n",
    "使用下面的代码单元（必要的话可以使用多个代码单元）来实现你项目。一旦你完成了你的实现并且获得了满意的结果，请确认全面回答下面相关的问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### 在这里实现你的代码 \n",
    "### 必要的话你可以随意添加更多的代码单元 \n",
    "\n",
    "# def split_softmax_entropy(y_predict, y_real):\n",
    "#     y_predict_spd = tf.reshape(y_predict, [-1, num_seqlen, num_labels])\n",
    "#     y_real_spd    = tf.reshape(y_real,    [-1, num_seqlen, num_labels])\n",
    "#     rtn = 0\n",
    "#     for i in range(0, num_seqlen):\n",
    "#         rtn += tf.reduce_mean(\n",
    "#         tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labs, logits=logits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 4\n",
    "_描述如何为模型准备训练和测试数据。 模型在真实数据集上表现怎么样？_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**回答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 5\n",
    "_你（在模型上）做了什么改变？如果做了一些改变，那么你得到一个“好的”结果了妈？有没有任何你探索的导致结果更糟？_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**回答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 6\n",
    "_当你在真实数据集做测试的时候你的初始结果和最终结果是什么？你认为你的模型在正确分类数字这个任务上上做的足够好吗？_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**回答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## 步骤 3: 在新抓取的图片上测试模型\n",
    "\n",
    "在你周围拍摄几张数字的图片（至少五张），然后用你的分类器来预测产生结果。或者（可选），你可以尝试使用OpenCV / SimpleCV / Pygame从网络摄像头捕获实时图像，并通过你的分类器分析这些图像。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实现\n",
    "使用下面的代码单元（必要的话可以使用多个代码单元）来实现你项目的。一旦你完成了你的实现并且获得了满意的结果，请确认全面回答下面相关的问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### 在这里实现你的代码  \n",
    "### 必要的话你可以随意添加更多的代码单元 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 7\n",
    "_选择在你周围拍摄的五张候选图片，并提供在报告中。它们中的某些图片是否有一些特殊的性质，可能会导致分类困难？_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**回答:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 8\n",
    "_与在现实数据集上的测试结果相比，你的模型能够在捕获的图片或实时相机流上表现同样良好吗？_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**回答:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可选: 问题 9\n",
    "_如果必要的话，请提供关于你是如何建立一个使得你的模型能够加载和分类新获取图像的接口的。_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**回答:** 如果你没有完成这个部分，那么这一块请保留空白"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### 步骤 4: 探索一种提升模型的方式\n",
    "\n",
    "一旦你基本的分类器训练好了，你就可以做很多事情。一个例子是：（在分类的同时）还能够定位图像上数字的位置。SVHN数据集提供边界框，你可以调试以训练一个定位器。训练一个关于坐标与边框的回归损失函数，然后测试它。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实现\n",
    "使用下面的代码单元（必要的话可以使用多个代码单元）来实现你项目的。一旦你完成了你的实现并且获得了满意的结果，请确认全面回答下面相关的问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### 在这里实现你的代码\n",
    "### 必要的话你可以随意添加更多的代码单元 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 10\n",
    "_你的模型在真实数据的测试集上定位数字表现的怎么样？包含位置信息之后你的分类结果有变化吗？_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**回答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题 11\n",
    "在你在**步骤3 **所捕获的图像上测试你的定位功能。模型是否准确计算出你找到的图像中的数字的边界框？如果你没有使用图形界面，您可能需要手动探索边界框。_提供一个在捕获的图像上创建边界框的示例_。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**回答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## 可选步骤 5：为模型封装一个应用或者是程序\n",
    "\n",
    "为了让你的项目更进一步。如果你有兴趣，可以构建一个安卓应用程序，或者是一个更鲁棒的Python程序。这些程序能够和输入的图像交互，显示分类的数字甚至边界框。比如，你可以尝试通过将你的答案叠加在图像上像[Word Lens](https://en.wikipedia.org/wiki/Word_Lens)应用程序那样来构建一个增强现实应用程序。\n",
    "\n",
    "如何在安卓上的相机应用程序中加载TensorFlow的模型的示例代码在[TensorFlow Android demo app](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android)中，你可以再这个基础上做一些简单的修改。\n",
    "\n",
    "\n",
    "如果你决定探索这条可选路径，请务必记录你的接口和实现，以及你找到的重要结果。你可以通过[点击这个链接](https://review.udacity.com/#!/rubrics/413/view)看到将被用来评价你的工作的相关条目。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可选 实现\n",
    "使用下面的代码单元（必要的话可以使用多个代码单元）来实现你项目的。一旦你完成了你的实现并且获得了满意的结果，请确认全面回答下面相关的问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### 在这里实现你的代码  \n",
    "### 必要的话你可以随意添加更多的代码单元 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文档\n",
    "请提供额外的文档，这些文档要足以详细说明安卓应用程序或Python程序如何实现可视化图像中数字的分类。你的描述应该清楚描述程序或应用程序的工作原理并提供一些演示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_在这里写你的文档_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **注意:** 当你写完了所有的代码，并且回答了所有的问题。你就可以把你的 iPython Notebook 导出成 HTML 文件。你可以在菜单栏，这样导出**File -> Download as -> HTML (.html)**把这个 HTML 和这个 iPython notebook 一起做为你的作业提交。"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-gpu]",
   "language": "python",
   "name": "conda-env-tensorflow-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
